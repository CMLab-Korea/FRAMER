<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="FRAMER: Frequency-Aligned Self-Distillation with Adaptive Modulation Leveraging Diffusion Priors for Real-World Image Super-Resolution">
  <meta name="keywords" content="FRAMER, Super-Resolution, Diffusion Models, Computer Vision, Real-ISR, CVPR">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FRAMER: Real-World Image Super-Resolution</title>
  <link rel="icon" type="image/svg+xml" href="./images/icon.svg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>

  <style>
    /* --- CMLab Identity & Dark Theme --- */
    :root {
        --lab-color: #0D207F;     /* CMLab Official Blue */
        --lab-light: #4c6ef5;     /* Lighter Blue */
        --bg-color: #0f111a;      /* Deep Dark Background */
        --card-bg: #1a1c29;       /* Card Background */
        --text-color: #e0e0e0;
        --accent-gradient: linear-gradient(90deg, #4facfe 0%, #00f2fe 100%);
    }

    body {
        background-color: var(--bg-color);
        color: var(--text-color);
        font-family: 'Google Sans', sans-serif;
        line-height: 1.6;
    }

    /* Typography & Links */
    .title { color: #ffffff !important; }
    .subtitle { color: #b0b0b0 !important; }
    a { color: var(--lab-light); transition: color 0.3s ease; }
    a:hover { color: #fff; text-decoration: underline; }

    strong {
        color: var(--lab-light);
        font-weight: 700;
    }

    /* Gradient Text */
    .gradient-text {
        background: var(--accent-gradient);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-size: 200% auto;
        animation: shine 4s linear infinite;
        font-weight: 800;
    }
    @keyframes shine { to { background-position: 200% center; } }

    /* Buttons */
    .button.is-dark-custom {
        background: rgba(255, 255, 255, 0.05);
        backdrop-filter: blur(10px);
        color: white;
        border: 1px solid rgba(255, 255, 255, 0.1);
        transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
    }
    .button.is-dark-custom:hover {
        background: var(--lab-color);
        border-color: var(--lab-light);
        box-shadow: 0 0 20px rgba(13, 32, 127, 0.6);
        transform: translateY(-3px);
    }

    /* --- [CORE FIX] Slider Styling --- */
    .slider-container {
        width: 100%;
        aspect-ratio: 1 / 1; 
        overflow: hidden;
        border-radius: 12px;
        position: relative;
        background: #000; 
    }
    
    img-comparison-slider {
        --divider-width: 2px;
        --divider-color: #00f2fe; 
        --default-handle-opacity: 1;
        width: 100%;
        height: 100%; 
        outline: none;
    }

    img-comparison-slider img {
        width: 100%;
        height: 100%;
        object-fit: cover; 
        object-position: center;
        display: block;
    }

    .slider-shadow {
        box-shadow: 0 20px 50px rgba(0,0,0,0.6);
        transition: box-shadow 0.3s ease;
    }
    .slider-shadow:hover {
        box-shadow: 0 30px 60px rgba(13, 32, 127, 0.4);
    }

    /* Badge Styling */
    img-comparison-slider figcaption {
        background: rgba(0, 0, 0, 0.8);
        color: white;
        padding: 5px 10px;
        border-radius: 4px;
        position: absolute;
        top: 20px;
        font-size: 0.85rem;
        font-weight: 800;
        text-transform: uppercase;
        letter-spacing: 0.5px;
        pointer-events: none;
        backdrop-filter: blur(2px);
        line-height: 1;
    }
    .before figcaption { left: 20px; color: #fff; }
    .after figcaption { right: 20px; color: #00f2fe; }

    /* Layout Boxes */
    .tldr-box {
        background: rgba(13, 32, 127, 0.15);
        border-left: 4px solid var(--lab-color);
        padding: 2rem;
        border-radius: 8px;
        margin-bottom: 3rem;
    }
    .glass-box {
        background: rgba(255, 255, 255, 0.03);
        border: 1px solid rgba(255, 255, 255, 0.05);
        padding: 25px; 
        border-radius: 16px;
        height: 100%; 
        display: flex;
        flex-direction: column;
        justify-content: flex-start;
    }

    /* Section Headers */
    .section-title {
        margin-bottom: 2rem;
        text-align: center;
        position: relative;
        display: inline-block;
        padding-bottom: 10px;
    }
    .section-title::after {
        content: '';
        position: absolute;
        width: 60px;
        height: 3px;
        background: var(--lab-light);
        bottom: 0;
        left: 50%;
        transform: translateX(-50%);
    }

    /* Footer */
    .footer { background-color: #050505; padding: 4rem 1.5rem; }
    
    .project-icon {
        width: 120px; 
        height: auto;
        margin-bottom: 1rem;
        filter: drop-shadow(0 0 15px rgba(255,255,255,0.2));
    }
    
    .method-title {
        color: var(--lab-light);
        margin-bottom: 10px;
        font-weight: 700;
        border-bottom: 1px solid rgba(255,255,255,0.1);
        padding-bottom: 10px;
    }

    /* [Modification] All PNGs get a white background to fix visibility of transparent diagrams */
    img[src$=".png"] {
        background-color: white;
    }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          
          <div style="display: flex; flex-direction: column; align-items: center; justify-content: center; margin-bottom: 15px;">
             <img src="./images/icon.svg" class="project-icon" alt="FRAMER Icon">
             
             <h1 class="title is-1 publication-title" style="margin-top: 0; line-height: 1;">
                <span class="gradient-text" style="font-size: 4.5rem;">FRAMER</span>
             </h1>
          </div>

          <h2 class="title is-3 publication-title">
            Frequency-Aligned Self-Distillation with Adaptive Modulation<br>
            Leveraging Diffusion Priors for Real-World Image Super-Resolution
          </h2>
          
          <div class="is-size-5 publication-authors" style="margin-top: 25px;">
            <span class="author-block">
              <a href="mailto:choiseungho1019@gmail.com">Seungho Choi</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="mailto:jhseong@cau.ac.kr">Jeahun Sung</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://cmlab-korea.github.io/" target="_blank">Jihyong Oh</a><sup>1,†</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Chung-Ang University</span>
          </div>
          <div style="margin-top: 10px;">
             <span style="font-weight: bold; font-size: 1.2rem; color: #fff;">
                Creative Vision and Multimedia Lab (CMLab)
             </span>
          </div>
          <div class="is-size-7" style="color: #888; margin-top: 5px;">
            <sup>†</sup>Corresponding Author
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2412.xxxx" class="external-link button is-normal is-rounded is-dark-custom">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/cmlab-korea/FRAMER" class="external-link button is-normal is-rounded is-dark-custom">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      
      <div class="tldr-box">
          <h3 class="title is-4" style="color: var(--lab-light); margin-bottom: 0.5rem;">TL;DR</h3>
          <p class="is-size-5">
              <strong>FRAMER</strong> unlocks the high-frequency potential of diffusion models for Real-World Super-Resolution without altering inference. 
              We demonstrate superior performance across both <strong>DiT (FRAMER<sub>D</sub>)</strong> and <strong>U-Net (FRAMER<sub>U</sub>)</strong> backbones by addressing the "low-first, high-later" frequency hierarchy.
          </p>
      </div>

      <h2 class="title is-3 section-title">Restoration Capability</h2>
      
      <div class="columns is-centered is-variable is-6">
        
        <div class="column is-6 has-text-centered">
            <div class="glass-box">
                <h3 class="title is-4" style="margin-bottom: 15px;">
                    <span class="gradient-text">FRAMER<sub>D</sub></span> <span class="is-size-6" style="color:#aaa">(DiT Backbone)</span>
                </h3>
                <div class="slider-container">
                    <img-comparison-slider class="slider-shadow">
                      <figure slot="first" class="before">
                        <img src="./images/tiger_lr.png" alt="LR Input">
                        <figcaption>LR INPUT</figcaption>
                      </figure>
                      <figure slot="second" class="after">
                        <img src="./images/tiger_framer.png" alt="FRAMER_D">
                        <figcaption>FRAMER<sub>D</sub></figcaption>
                      </figure>
                    </img-comparison-slider>
                </div>
                <p class="is-size-6 has-text-left" style="margin-top: 15px; color: #ccc;">
                    Restores intricate fur textures and fine details, overcoming the smoothing artifacts typical of diffusion models.
                </p>
            </div>
        </div>

        <div class="column is-6 has-text-centered">
            <div class="glass-box">
                <h3 class="title is-4" style="margin-bottom: 15px;">
                    <span class="gradient-text">FRAMER<sub>U</sub></span> <span class="is-size-6" style="color:#aaa">(U-Net Backbone)</span>
                </h3>
                <div class="slider-container">
                    <img-comparison-slider class="slider-shadow">
                      <figure slot="first" class="before">
                        <img src="./images/aurora_lr.png" alt="LR Input">
                        <figcaption>LR INPUT</figcaption>
                      </figure>
                      <figure slot="second" class="after">
                        <img src="./images/aurora_framer.png" alt="FRAMER_U">
                        <figcaption>FRAMER<sub>U</sub></figcaption>
                      </figure>
                    </img-comparison-slider>
                </div>
                <p class="is-size-6 has-text-left" style="margin-top: 15px; color: #ccc;">
                    Effectively sharpens natural landscapes and starry skies, demonstrating robust generalization on the U-Net architecture.
                </p>
            </div>
        </div>
      </div>
      
      <div class="content has-text-centered is-size-6" style="color: #666; margin-top: 20px;">
        <i class="fas fa-arrows-alt-h"></i> Slide the handle to compare <strong>Low-Resolution Input</strong> vs <strong>FRAMER Restoration</strong>.
      </div>

    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 section-title">Abstract</h2>
        <div class="content has-text-justified is-size-5">
          <p>
            Real-image super-resolution (Real-ISR) seeks to recover HR images from LR inputs with mixed, unknown degradations. 
            While diffusion models surpass GANs in perceptual quality, they under-reconstruct high-frequency (HF) details due to a <strong>low-frequency (LF) bias</strong> and a depth-wise <strong>"low-first, high-later" hierarchy</strong>.
          </p>
          <p>
            We introduce <strong>FRAMER</strong>, a plug-and-play training scheme that exploits diffusion priors without changing the backbone or inference. 
            At each denoising step, the final-layer feature map teaches all intermediate layers. Teacher and student feature maps are decomposed into LF/HF bands via FFT masks to align supervision with the model's internal frequency hierarchy.
          </p>
          <p>
            For LF, an <strong>Intra Contrastive Loss (IntraCL)</strong> stabilizes globally shared structure. For HF, an <strong>Inter Contrastive Loss (InterCL)</strong> sharpens instance-specific details using random-layer and in-batch negatives. 
            Two adaptive modulators, <strong>Frequency-based Adaptive Weight (FAW)</strong> and <strong>Frequency-based Alignment Modulation (FAM)</strong>, reweight per-layer LF/HF signals and gate distillation by current similarity. 
            Across U-Net and DiT backbones, FRAMER consistently improves PSNR/SSIM and perceptual metrics (LPIPS, NIQE, MANIQA, MUSIQ).
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered section-title">Motivation & Analysis</h2>
      
      <div class="columns is-centered is-vcentered">
        <div class="column is-6">
            <img src="./images/figure_3.png" alt="Layer-wise Cosine Similarity" style="border-radius: 8px; border: 1px solid #333; width: 100%;">
            <p class="is-size-7 has-text-centered" style="color: #888;">
                Layer-wise cosine similarity of LF/HF features in diffusion models.
            </p>
        </div>
        <div class="column is-6">
            <div class="content has-text-justified">
                <h4 class="title is-4">The "Low-First, High-Later" Hierarchy</h4>
                <p>
                    We trace the limitations of current diffusion models in Real-ISR to a fundamental <strong>low-frequency (LF) bias</strong> stemming from two key observations:
                </p>
                <ul>
                    <li>
                        <strong>Spectral Bias:</strong> Natural image frequency distributions are inherently LF-dominant. The standard noise-prediction loss thus favors these dominant LF components, inevitably undertraining HF signals.
                    </li>
                    <li>
                        <strong>Depth-wise Hierarchy:</strong> As shown in the figure, an analysis of layer-wise feature maps reveals that LF features stabilize early in the network, while <strong>HF features converge only near the final layers</strong>.
                    </li>
                </ul>
                <p>
                    A conventional, frequency-agnostic loss is fundamentally misaligned with this hierarchy. It supplies redundant gradients to early layers while starving the later, HF-refining layers. FRAMER addresses this by aligning distillation signals with this internal progression.
                </p>
            </div>
        </div>
      </div>
    </div>
</section>
  
<section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered section-title">Method Overview</h2>
      <div class="columns is-centered">
        <div class="column is-full-width has-text-centered">
           <img src="./images/method.png" alt="FRAMER Framework" style="border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.5);">
        </div>
      </div>
      <div class="content has-text-left" style="margin-top: 25px;">
        <p class="is-size-5 has-text-justified">
           <strong>Figure 4.</strong> Overview of FRAMER. The framework applies self-distillation from the final-layer teacher to intermediate student layers. We decompose teacher/student features into LF/HF bands via FFT masks. The key components are:
        </p>
        
        <div class="columns is-multiline" style="margin-top: 10px;">
            <div class="column is-6">
                <div class="glass-box">
                    <h5 class="title is-5 method-title">IntraCL (LF)</h5>
                    <p class="has-text-left"><strong>Intra Contrastive Loss</strong> stabilizes globally shared structures. It compares a student only against its teacher and a randomly sampled layer within the same network (no in-batch negatives), preventing false negatives common in batch-based contrastive learning.</p>
                </div>
            </div>
            <div class="column is-6">
                <div class="glass-box">
                    <h5 class="title is-5 method-title">InterCL (HF)</h5>
                    <p class="has-text-left"><strong>Inter Contrastive Loss</strong> sharpens instance-specific details. It targets HF bands using both random-layer negatives (for layer progression) and in-batch negatives (for instance discrimination), counteracting the LF bias.</p>
                </div>
            </div>
            <div class="column is-6">
                <div class="glass-box">
                    <h5 class="title is-5 method-title">FAW</h5>
                    <p class="has-text-left"><strong>Frequency-based Adaptive Weight</strong> decomposes self-distillation across depth and frequency. It reweights supervision based on the actual layer-wise change rate relative to the final layer, mitigating scale-induced spectral bias.</p>
                </div>
            </div>
            <div class="column is-6">
                <div class="glass-box">
                    <h5 class="title is-5 method-title">FAM</h5>
                    <p class="has-text-left"><strong>Frequency-based Alignment Modulation</strong> gates the distillation strength based on student-teacher alignment. It suppresses large, unstable gradients in early layers when alignment is low, preventing early training collapse.</p>
                </div>
            </div>
        </div>
      </div>
    </div>
</section>
  
<section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered section-title">Quantitative Results</h2>
      
      <div class="columns is-centered">
        <div class="column is-10 has-text-centered">
            <img src="./images/table_1.png" alt="Table 1: Quantitative Comparison" style="width: 100%; border-radius: 8px; box-shadow: 0 10px 30px rgba(0,0,0,0.5);">
            
            <div class="content has-text-justified" style="margin-top: 15px; color: #bbb;">
                <p>
                    <strong>Table 1.</strong> Quantitative comparison of real-world image super-resolution methods. We evaluate fidelity metrics (PSNR, SSIM, LPIPS) as well as perceptual quality metrics (NIQE, MANIQA, MUSIQ) across multiple datasets, including <strong>DrealSR</strong>, <strong>RealSR</strong>, <strong>RealLR200</strong>, and <strong>RealLQ250</strong>. Overall, our method demonstrates competitive and generally superior performance across perceptual quality metrics.
  
                </p>
            </div>
        </div>
      </div>
    </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered section-title">Qualitative Comparisons</h2>
        <p class="subtitle has-text-centered">
            Detailed visual comparisons against state-of-the-art methods.
        </p>
        
        <div class="columns is-multiline is-centered" style="margin-top: 30px;">
            
            <div class="column is-12 has-text-centered">
                <div class="glass-box">
                    <h4 class="title is-4 has-text-centered" style="margin-bottom: 20px;">
                        <span style="color: var(--lab-light);">Synthetic Degradation</span> (DrealSR, RealSR Dataset)
                    </h4>
                    <img src="./images/figure_10.png" alt="Figure 10: Comparisons on datasets with Ground Truth" style="width: 100%; border-radius: 8px; box-shadow: 0 10px 30px rgba(0,0,0,0.5);">
                    <p class="is-size-6 has-text-justified mt-4" style="color: #ccc;">
                        <strong>Figure 10.</strong> Qualitative comparisons on datasets with Ground Truth (DrealSR, RealSR). We compare FRAMER against state-of-the-art methods (SwinIR, ResShift, SeeSR, PiSA-SR, DreamClear, DiT4SR). 
                        Red arrows indicate structural errors (e.g., hallucinations, object distortion), while Yellow arrows point to textural defects. FRAMER consistently mitigates these artifacts, producing sharper edges and faithful textures.
                    </p>
                </div>
            </div>

            <div class="column is-12 has-text-centered" style="margin-top: 40px;">
                <div class="glass-box">
                    <h4 class="title is-4 has-text-centered" style="margin-bottom: 20px;">
                        <span style="color: var(--lab-light);">Real-World "In-the-Wild"</span> (RealLR200, RealLQ250 Dataset)
                    </h4>
                    <img src="./images/figure_11.png" alt="Figure 11: Comparisons on datasets without Ground Truth" style="width: 100%; border-radius: 8px; box-shadow: 0 10px 30px rgba(0,0,0,0.5);">
                    <p class="is-size-6 has-text-justified mt-4" style="color: #ccc;">
                        <strong>Figure 11.</strong> Qualitative comparisons on datasets without Ground Truth (RealLR200, RealLQ250). In these real-world scenarios with unknown degradations, baseline methods often suffer from severe degradations (red arrows indicate structural failures, yellow indicate textural anomalies). 
                        FRAMER demonstrates superior perceptual quality by effectively balancing noise suppression with detail generation.
                    </p>
                </div>
            </div>

        </div>
    </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{choi2025framer,
  title={FRAMER: Frequency-Aligned Self-Distillation with Adaptive Modulation Leveraging Diffusion Priors for Real-World Image Super-Resolution},
  author={Choi, Seungho and Sung, Jeahun and Oh, Jihyong},
  journal={arXiv preprint arXiv:2412.xxxx},
  year={2025}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
        <div style="margin-bottom: 20px;">
            <h4 class="title is-5" style="color: white; letter-spacing: 2px;">CMLab</h4>
        </div>
        
      <p class="is-size-7" style="color: #666;">
        This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.<br>
        Website template adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
      </p>
      
      <div style="margin-top: 10px; color: #444;">
          <span class="icon"><i class="fas fa-eye"></i></span> <span>Page Views: <span style="color: var(--lab-light);">1,402</span></span>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
